{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WbcHpdIWV3UI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "colab = True\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    colab = True\n",
    "else:\n",
    "    colab = False\n",
    "\n",
    "if colab:\n",
    "    module_path = os.path.abspath(os.path.join('./real-hdd-failure/code/'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "    helper_path = os.path.abspath(os.path.join('./real-hdd-failure/code/helper/'))\n",
    "    if helper_path not in sys.path:\n",
    "        sys.path.append(helper_path)\n",
    "    !{sys.executable} -m pip install -r ./real-hdd-failure/requirements.txt\n",
    "else:\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "    helper_path = os.path.abspath(os.path.join('../helper'))\n",
    "    if helper_path not in sys.path:\n",
    "        sys.path.append(helper_path)\n",
    "# !{sys.executable} -m pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oFsQJXjUYWX",
    "outputId": "e735667e-d155-4e49-be54-9e937d254ff3"
   },
   "outputs": [],
   "source": [
    "from helper.dataclass import HDDDataset\n",
    "from helper.algorithms.Blending import Blending\n",
    "from helper.algorithms.Stacking import Stacking\n",
    "from helper.preprocessing import *\n",
    "from helper.metrics import *\n",
    "from helper.eda import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helper.metrics import *\n",
    "from helper.saver import Saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glNRJEmjUYWX"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "-a3s8McIUYWY",
    "outputId": "e6d43baf-835d-4641-c8d7-e01a21078ffd"
   },
   "outputs": [],
   "source": [
    "hdd_dataset = HDDDataset.read_csv('ST14000NM001G.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mk7zbLFUYWY",
    "outputId": "93e674a1-ebbe-4595-a3cc-655068b1a345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing unused columns...\n",
      "Adding target column...\n",
      "Prepairing train dataset...\n",
      "Adding time features to unsplitted dataset...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Некорректное значение oversampling",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39mprepare_train_df()\n\u001b[0;32m      5\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39madd_time_features()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_val_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.055\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moversampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSmote\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39mnormalize_data(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformulae\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# preprocessor.normalize_data(method='YJ', inplace=True)\u001b[39;00m\n",
      "File \u001b[1;32mg:\\real-hdd-failure\\code\\helper\\preprocessing.py:241\u001b[0m, in \u001b[0;36mPreprocessing.train_test_val_split\u001b[1;34m(self, train_size, val_size, test_size, sampling_strat, oversampling, undersampling)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_size \u001b[38;5;241m+\u001b[39m val_size \u001b[38;5;241m+\u001b[39m test_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sampling_strat \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (sampling_strat \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sampling_strat \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mНекорректное значение sampling_strat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m oversampling \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBorderline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTomek\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdasyn\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mНекорректное значение oversampling\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m undersampling \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTomek\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNearMiss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mНекорректное значение undersampling\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplitting train dataset...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Некорректное значение oversampling"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessing(hdd_dataset)\n",
    "preprocessor.clear_unused_data()\n",
    "preprocessor.add_target_column()\n",
    "preprocessor.prepare_train_df()\n",
    "preprocessor.add_time_features()\n",
    "preprocessor.train_test_val_split(sampling_strat=0.055, oversampling='Default')\n",
    "preprocessor.normalize_data(method='formulae', inplace=True)\n",
    "# preprocessor.normalize_data(method='YJ', inplace=True)\n",
    "preprocessor.drop_unimportant_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaling types...\n"
     ]
    }
   ],
   "source": [
    "preprocessor.rescale_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDbUU4j2UYWY"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aJDYsQaUUYWZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Обучаем MLPClassifier...  ===\n",
      "=== Обучаем RandomForestClassifier...  ===\n",
      "=== Обучаем CatBoostClassifier...  ===\n",
      "=== Обучаем мета модель... ===\n"
     ]
    }
   ],
   "source": [
    "model = Blending(models=[\n",
    "    MLPClassifier(activation='relu', alpha=0.43, batch_size=350, beta_1=0.85, beta_2=0.9, hidden_layer_sizes=(128, 64), learning_rate='adaptive', learning_rate_init=0.1, solver='adam'),\n",
    "    RandomForestClassifier(bootstrap=False, criterion='gini', max_features=0.21, min_samples_leaf=9, min_samples_split=3, n_jobs=-1),\n",
    "    CatBoostClassifier(thread_count=-1, verbose=0)\n",
    "    ])\n",
    "preds = model.fit_predict(preprocessor.X_train, preprocessor.y_train, preprocessor.X_val, preprocessor.y_val, preprocessor.X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdGrZuB5UYWZ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PvDy8QtQUYWZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9996530130488951, 'precision': 0.9779411764705882, 'recall': 0.5175097276264592, 'f1': 0.6768447837150128, 'auc_roc': 0.7587507626624467}\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics.get_metrics(preds, preprocessor.y_test)\n",
    "print(metrics)\n",
    "# Посмотрим метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC61gWrfUYWZ"
   },
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ROHs7GPWUYWa"
   },
   "outputs": [],
   "source": [
    "Saver.save(model, preprocessor, metrics, save_csv=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
